{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93e2c282-73b3-4371-b086-e3cd2fc9b595",
   "metadata": {},
   "source": [
    "# Luentoviikko 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c608ba-dd93-4759-814b-9eaa73cb8a19",
   "metadata": {},
   "source": [
    "## Luennon tärkeimmät pointit\n",
    "***\n",
    "Viidennellä luentoviikolla en päässyt itse paikalle, joten katsoin viimevuoden saman aihealueen vierailuluennon. Luennolla käsiteltiinkin luonnollisen kielen analyysiä, ja sen käyttämistä liiketoimintaympäristössä. \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c122bf4-c135-45ad-970a-f5b29524ce05",
   "metadata": {},
   "source": [
    "#### 1:\n",
    "Luonnollisen kielen analyysi (eng. Natural Language Processing, NLP) tarkoittaa ihmisten käyttämän kielen analysointiin koneoppimisen menetelmien avulla. Koska kieli ei itsessään ole rakenteellista vaan orgaanisesti syntynyttä, tuottaa siitä tiedon kerääminen ongelman informaation tarkassa keräämisessä. Luennolla mainittiin näkyvimmäksi esimerkiksi verkkokauppojen chatbotit, jotka ovat myös hyvä esimerkki liiketoimintasovelluksesta luonnollisen kielen analyysille. Chatbotit vastaanottavat asiakkaiden kysymyksiä, ja pyrkivät tuomaan asiakkaalle nopeasti vastauksen ilman, että asiakkaan tarvitsee erikseen ottaa yhteyttä asiakaspalveluun. Tällä tavoin yritys voi säästää asiakaspalvelun kustannuksista, sekä samalla parantaa asiakkaiden kokemusta verkkokaupassa asioinnista.\n",
    "\n",
    "#### 2:\n",
    "Luonnollisen kielen analyysissä yksi, sekä tärkein ongelmakohta on esikäsittely sekä piirteiden erottaminen saadusta datasta. Luonnollinen kieli sisältää paljon sanoja, jotka eivät itsessään kanna tietoarvoa lopullisen analytiikan kannalta. Kyseisiä sanoja kutsutaan hukkasanoiksi, ja ne pyritäänkin poistamaan datasta esikäsittelyssä. Kontekstuaalisuus on kuitenkin yleinen ongelma hukkasanojen poistamisessa, sillä eri aihetta käsiteltäessä yleinen hukkasana voi saada tärkeänkin merkityksen lopullisen viestin kannalta. \n",
    "\n",
    "#### 3:\n",
    "Datan analysointiprosessissa noudatetaan NLP:n tapauksessa normaalia data-analytiikan prosessia (Discover, Access, Distill). Prosessin alussa etsitään sopiva koulutusdata, jota malliin kyetään hyödyntämään. Toisessa vaiheessa data kerätään, ja kolmannessa siitä erotellaan piirteet ja siirrytään mallin rakentamiseen. Edellisessä kohdassa mainitun kontekstuaalisuuden takia on kuitenkin oikean datan keräämisessä ongelma, sillä pelkästään satunnaisten tekstikappaleiden käyttäminen mallille ei toimi, vaan mallin koulutusdatan ja lopullisen ennustettavan tai muun halutun datan välillä tulee olla jokin yhteys, käyttökohteesta riippuen. Samalla mallin tulee olla riittävän yleistettävissä, jotta se kykenee suoriutumaan tehtävästään. Jos malli koulutetaan liian yksipuolisesti (esim. vain yhden lähteen avulla), voi malli olla tehokas ennustamaan vain koulutusdataan liittyviä piirteitä.\n",
    "\n",
    "#### 4:\n",
    "Yliotanta ja aliotanta ovat tapoja, jolla koneoppimisessa kyetään joko synteettisesti luomaan datapisteitä tai vähentämään niiden määrää. Edelliseen pointtiin liittyen, yksi mahdollinen tapa tasoittaa saatavilla olevaa dataa onkin luoda lisää datapisteitä jotta yksi koulutuskohde ei ole yliedustettuna. Luonnollisen kielen analyysissä tämä on kuitenkin erittäin hankalaa, sillä koulutusta varten tarvittaisiin lisää luonnollista tekstiä. Aliotanta, datassa yliedustettujen luokkien karsinta, onkin helpoin vaihtoehto mutta samalla vähentää mallin koulutukseen käytettävän datan määrää.\n",
    "\n",
    "#### 5:\n",
    "Esikäsittelyn tarkoitus on luonnollisen kielen analyysissä, sekä myös muussa koneoppimisessa, parantaa halutun mallin opetusdatan laatua ja siten tarkkuutta kohinaa vähentämällä. NLP:n tapauksessa tärkeä elementti on muuttaa tekstimuotoinen data sellaiseen muotoon, että sitä kyetään käyttää mallin opettamisessa. Prosessi, jolla NLP ongelmaa lähdetäänkin ratkomaan, on yleensä seuraava:\n",
    "\n",
    "1. Korpus, täysi datasetti\n",
    "2. Esikäsittely: Pienien alkukirjainten vaihto jokaiseen sanaan, erikoismerkkien poisto, hukkasanojen poisto, perusmuotoistaminen siten, että sanan alkuperäinen merkity ei muutu, stemmaus, jossa sanan pääte katkaistaan\n",
    "3. Piirteiden erottaminen esimerkiksi sanavektorien avulla\n",
    "4. Ulottuvuuksien vähentäminen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9395a922-f7ab-4f00-b10b-6dc02e123482",
   "metadata": {},
   "source": [
    "# Kehitysvinkit\n",
    "Enemmän esimerkkejä käytännön hyödyntämisestä ja muista liiketoimintamahdollisuuksista."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f842e5b4-fa6c-45cf-a775-76fe590bd375",
   "metadata": {},
   "source": [
    "# Koodi\n",
    "Koodin esimerkki on suoraan lainattu https://fasttext.cc/docs/en/supervised-tutorial.html FastText- tutoriaalista, ja osoittaa kuinka helppoa mallin rakentaminen kirjaston avulla on. Mallissa ei esikäsitellä dataa mitenkään, vaan kaikki käytettävä data on raakadataa stack exchangen kokkaus osiosta (https://cooking.stackexchange.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed12cc2a-bfbd-46c2-aefb-71b67f7697d5",
   "metadata": {},
   "source": [
    "#### Komentoriville:\n",
    "1. wget https://dl.fbaipublicfiles.com/fasttext/data/cooking.stackexchange.tar.gz && tar xvzf cooking.stackexchange.tar.gz\n",
    "2. wc cooking.stackexchange.txt\n",
    "3. head -n 12404 cooking.stackexchange.txt > cooking.train\n",
    "4. tail -n 3000 cooking.stackexchange.txt > cooking.valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "383870b1-11c1-4d4b-8016-a1ff67cea70c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fasttext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Haetaan fasttext- kirjasto\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfasttext\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m## Luodaan malli ja annetaan sille argumentiksi koulutustiedosto\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m fasttexts\u001b[38;5;241m.\u001b[39mtrain_supervised(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcooking.train\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fasttext'"
     ]
    }
   ],
   "source": [
    "## Haetaan fasttext- kirjasto\n",
    "import fasttext\n",
    "## Luodaan malli ja annetaan sille argumentiksi koulutustiedosto\n",
    "model = fasttexts.train_supervised(input=\"cooking.train\")\n",
    "## Tallennetaan malli\n",
    "model.save_model(\"model_cooking.bin\")\n",
    "## Ennustetaan, mikä Labeli sopii kysymykseen\n",
    "model.predict(\"Which baking dish is best to bake a banana bread ?\")\n",
    "## Kokeillaan toista lausetta\n",
    "model.predict(\"Why not put knives in the dishwasher?\")\n",
    "## Kokeillaan, kuinka hyvin malli kykenee ennustamaan labelin\n",
    "model.test(\"cooking.valid\")\n",
    "## Uusi testi, muuta tarkkuus ja palautus asetetaan olemaan 5\n",
    "model.test(\"cooking.valid\", k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6dbac3-d144-45b5-beba-33c0d9195a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Koetetaan samaa ennustamista, mutta kysytään parasta viittä\n",
    "## ennustetta.\n",
    "model.predict(\"Why not put knives in the dishwasher?\", k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "392f0c89-943f-40e6-b5bb-b2352252c546",
   "metadata": {},
   "source": [
    "# Luentoviikko 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd240e7-c277-4d4a-82e5-cd7877a0d9f0",
   "metadata": {},
   "source": [
    "## Luennon tärkeimmät pointit\n",
    "***\n",
    "Kolmannella luentoviikolla kävimme läpi koneoppimisen käyttöä osana datatieteitä sekä tukena eri päätöksissä. Luennolla käytiin läpi sentimenttianalyysin tekeminen tekstitiedostoista sekä luonnollisen kielen analysointi osana koneoppimista, sekä luokitteluongelma eri piirteiden perusteella luottokortin myöntämispäätösten muodossa. Luennon lopuksi kävimme myös läpi nopeasti datatieteissä yleisesti esille nousevia ongelmia. En itse päässyt luennolle paikalle, mutta katsoin tallenteen panoptosta luennon jälkeen.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2036cec-894b-468e-a8de-d61e077586a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1:\n",
    "Koneoppiminen tarkoittaa algoritmin opettamista huomaamaan tietyt säännöt ja toistuvat elementit datasetistä, ja tällätavoin eroaakin tekoälystä vaikkakin joissain sovelluksissa termejä käytetään ristiin. Koneoppimisella ei pyritä rakentamaan yhtä laajoja algoritmeja, vaan käyttökohde on hyvin määritelty ongelma kuten esimerkiksi datan lajittelu oikesiin kategorioihin. Käyttökohteiltaan koneoppiminen, kuten luennolla mainittiinkin, ei sinällään ole muuta kuin yksi työkalu datatieteilijän käytössä. Koneoppiminen ei siis toimi ratkaisuna kaikkeen, vaan tukitoimintona oikeissa paikoissa. Esimerkiksi  puhtaasti tutkittavan ilmiön ymmärtämisen kannalta voi hyödyllisempää olla käyttää tilastollisia menetelmiä, kuin puhtaasti koneoppimista.  \n",
    "\n",
    "#### 2:\n",
    "Koneoppimista voidaan suorittaa monella eri tyylillä: ohjatulla, ohjaamattomalla, vahvistetulla tai syväoppimismetodilla. Ohjattu oppiminen tarkoittaa labeloidun datasetin antamista mallille, josta malli pyrkii luomaan ennusteita tai kategorisoimaan uutta syötettyä dataa. Ohjatun oppimisen työnkulku alkaa datan keräämisellä ja labeleiden luomisella. Jossain tilanteissa labelit joudutaan asettamaan datalle itse manuaalisesti. Labeleiden asettamisen jälkeen erotellaan datasta piirteet, jotka toimivat labelia ennustavana muuttujana. Tämän jälkeen luodaan piirrematriisi jossa eri piirteet asetetaan sarakkaiden otsikoiksi ja labelit rivien otsikoiksi, sekä kutakin labelia vastaavat piirteet omille paikoilleen. Tämän jälkeen voidaankin jo siirtyä mallin opettamiseen ja tarkkuuden arviointiin, sekä tästä eteenpäin käyttöönottoon.\n",
    "\n",
    "#### 3:\n",
    "Piirteillä tarkoitetaan koneoppimisen työjärjestyksessä eri muuttujien ennustamiseen käytettäviä arvoja. Esimerkiksi henkilön jäljellä olevaa elinikää ennustettaessa voidaan elämäntapoja kuten tupakointia ja liikuntaa pitää piirteinä, ja elinikää luokkana jota ennustaa esimerkiksi regression avulla. Piirteitä joudutaan usein jalostamaan osana koneoppimisprosessia esimerkiksi standardoimalla, poistamalla kohinaa tai vähentämällä tai kasvattamalla ominaisuuksia. Luennolla esimerkiksi piirteistä tuotiin luottokortin hakijan ominaisuudet, kuten luottotietojen olemassaolo ja tulotaso. Koneoppimisen ja piirteiden käyttämisessä tällä tavoin tulee kuitenkin huomioida myös eettiset huolet sekä liiketoimintamerkitys, sillä malli ei ole koskaan täysin tarkka. Esimerkiksi, jos kaikille hakijoille myönnetään luottokortti, kun tiedetään 95 % maksavan laskunsa ajoissa, vältetään virheellisten negatiivisten päätösten teko mutta samalla lisätään liiketoimintariskejä. Toisaalta luottokortin myöntäminen vain mallin kriteerit täyttäville henkilöille pienentäisi, ei poistaisi, virheellisten positiivisten riskiä, mutta samalla kasvattaisi virheellisten negatiivisten päätösten riskiä. Koneoppimismallien toiminnallisuus riippuu myös paljolti siitä datasetistä, jolla ne koulutetaan. Yksipuolisella datasetillä voidaan synnyttää tahattomasti- tai tahallisesti- syrjiviä liiketoimintapäätöksiä, kuten Čevora (2020) tuo artikkelissaan (1) ilmi.\n",
    "\n",
    "#### 4:\n",
    "Yksi tapa kerätä merkityksellistä tietoa on käyttää luonnollisen kielen algoritmeja, joiden avulla tekstimuotoista tietoa voidaan analysoida. Tällä tavoin voidaan suuresta määrästä tekstiä nostaa esille esimerkiksi usein toistuvat sanat jotka kuvaavat jotain keskustelun kohteen ominaisuutta. Luennolla esimerkkinä lunnollisen kielen käsittelyn käyttökohteesta käytettiin Nokian puhelimen Amazon arvostelujen dataa sekä vielä kiinnostavammin asiakaspoistuma-analyysiä (2, sama artikkeli mitä luennolla käytettiin mutta toimivalla linkillä). Asiakaspoistuma analyysiin voikin tuoda lunnollisen kielen prosessoinnilla milenkiintoista tietoa, jos vain on pääsy johonkin datasettiin, jonka avulla voidaan tutkia asiakkaiden palautteita. \n",
    "\n",
    "\n",
    "#### 5:\n",
    "Mahdollisia virheitä koneoppimisessa on paljon. Koneoppimista hyödynnettäessä tuleekin huomata, että loppujen lopuksi muodostettavat analyysit ovat riippuvaisia henkilöistä, jotka ovat kerääneet datan ja muodostaneet mallin. Luennon lopussa esitetyt virhepäätelmät eivät siis ole riippuvaisia data-analytiikasta ja sen virheellisestä käytöstä, vaan ihmisen sisään rakennetuista käyttäytymismalleista (Ks. Kahneman, \"Thinking, Fast and Slow,\" 2014). Virheiltä ei siis voida kokonaan välttyä, mutta organisaatio voi toimia niiden vaikutusten minimoinnin eteen.\n",
    "\n",
    "(1): https://towardsdatascience.com/how-discrimination-occurs-in-data-analytics-and-machine-learning-proxy-variables-7c22ff20792\n",
    "\n",
    "(2): https://bilot.group/articles/asiakaspoistuma-analyysi-ja-miljoona-lisamyyntia/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1be5f28-9c68-4532-abf1-9d4a79e7f80b",
   "metadata": {},
   "source": [
    "## Kehitysvinkit\n",
    "Lisälukemista NLP:stä olisi kiva saada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fca542-4a1c-450c-865d-548b8954117a",
   "metadata": {},
   "source": [
    "## Koodi\n",
    "Koska harjoitustyössä voidaan hyvin käyttää koneoppimista sekä luonnollisen kielen prosessointia, pyrin tässä nopeasti alustamaan harjoitustyötä varten NLP- prosessin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "224565f5-ad2e-47e9-93c5-433b8ccb3aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Haetaan tarvittavat kirjastot\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter\n",
    "comments = \"\"\n",
    "tokeni_lista = []\n",
    "tiheys = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "00ccc3aa-58b3-4aea-b706-c25fb0b582b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listing_id        int64\n",
      "id                int64\n",
      "date             object\n",
      "reviewer_id       int64\n",
      "reviewer_name    object\n",
      "comments         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "##Käytetään samaa datasettiä, mitä viimeksi\n",
    "reviews = pd.read_csv(\"reviews.csv.gz\")\n",
    "tdf = reviews.copy().iloc[:10]\n",
    "print(tdf.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "16bfa841-f274-48ba-a452-036dfe8fe5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", <, br/>The, accomation, needed, convienient, bus, tram]t, welcoming, host, room, light, charming, decorated, Daniel, great, sense, hospitality, helped, luggage, gave, maps, travelguide, He´s, open, minded, helpful, great, time, stay, anytime, we´re, Amsterdam, Daniel, sure, great, trip, thanks, bikes, Hope, soon, Daniel, Daniel, fantastic, host, place, calm, clean, provided, information, enjoy, amazing, city, Amsterdam, return, city, place, choice, Daniel, great, couldn.t, gone, lot, trouble, added, little, touch, apartment, speak, 5, languages, problem, way, noises, close, public, transportations, getting, city, fairly, easy, fast, highly, recommend, Daniele, place, \n"
     ]
    }
   ],
   "source": [
    "##Käydään läpi dataframe rivi riviltä\n",
    "for index, row in tdf.iterrows():  \n",
    "    lkp = spacy.lang.en.English() ##Purkkaa, ei jostain syystä meinannut toimia muuten\n",
    "    comments = str(row['comments']) ##Muutetaan objektista str muotoon\n",
    "    dokumentti = lkp(comments) ##Syötetään spacylle\n",
    "    for token in dokumentti: ##Käydään läpi spacyn antamat tokenit\n",
    "        if token.is_stop == False and token.is_punct == False: ##Poistetaan stoppisanat ja tunnistettavat välimerkit\n",
    "            tokeni_lista = tokeni_lista + [token] ##Lisätään listaan\n",
    "print(tokeni_lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "87bf52bd-d590-42c4-9b3d-8ac56afe1980",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nopeasti väännetty algoritmi frekvenssien määrittämiseen\n",
    "for i in range(len(tokeni_lista)):\n",
    "    tutkittava = str(tokeni_lista[i])\n",
    "    esiintymismaara = 0\n",
    "    for sana in tokeni_lista:\n",
    "        if tutkittava == str(sana):\n",
    "            esiintymismaara += 1\n",
    "    if esiintymismaara > 1:\n",
    "        tiheys[tutkittava] = esiintymismaara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a5be1518-493a-4227-b1bb-f009fc26abd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Daniel': 12, 'place': 8, 'clean': 8, 'quiet': 2, 'maps': 4, 'room': 4, 'trouble': 2, 'come': 2, 'amazing': 3, 'host': 8, 'extremely': 2, 'want': 2, 'mini': 2, 'fridge': 2, 'towels': 2, 'friendly': 2, 'helpful': 4, 'way': 2, 'needed': 3, 'recommended': 2, 'great': 9, 'time': 3, 'Amsterdam': 5, 'cozy': 2, 'comfortable': 4, 'provided': 4, 'tram': 3, 'took': 2, 'minutes': 2, 'city': 6, '\\r': 5, '<': 5, 'close': 2, 'bus': 2, 'enjoy': 2, 'stay': 3, ' ': 5, 'highly': 2, 'truly': 2, 'feel': 2, 'like': 2, 'local': 2, 'easy': 3, 'gave': 2, 'getting': 2, 'public': 2, 'Daniele': 3, 'br/': 3, '>': 3}\n"
     ]
    }
   ],
   "source": [
    "print(tiheys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16ae79d-079e-404c-8dcb-b7cb365c6e56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
